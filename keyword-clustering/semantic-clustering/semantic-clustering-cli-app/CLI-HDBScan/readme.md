# Semantic Keyword Clustering with Python - HDBScan Versions (Use This for Very Large Clustering Jobs!)

This Python script uses the power of the SentenceTransformers library to semantically cluster keywords. It utilizes the sentence embeddings generated by SentenceTransformers to find semantically similar keywords and group them together. The output is a CSV file or Excel file with Pivot Table containing original keywords and the group (cluster) to which they belong.

## Core Functionality

1. Load a CSV file that contains keywords.
2. Use SentenceTransformers to generate sentence embeddings.
3. Perform clustering on the embeddings to find groups of similar keywords.
4. Output the result as a CSV file, where each keyword is associated with a cluster name.
5. A treempa or sunburst chart is generated to visualise the clustering result.

## How to Use

The main entry point of the script is the main() function, which is decorated as a Typer command. The function accepts several arguments to control the behavior of the script.

Here's an example of how to run the script:

`python cluster.py mycsv.csv --column_name "Keyword" --output_path "output.csv" --chart_type "sunburst" --device "cpu" --model_name "all-MiniLM-L6-v2" --min_similarity 0.80 --remove_dupes True --volume "Volume" --stem True`

Minimal example:

`python cluster.py mycsv.csv`

Replace mycsv.csv with the path to your CSV file.

## Options

* `file-path:` The path to your CSV file.
* `column-name:` The name of the column in your CSV to be processed.
* `output-path:` The path where the output CSV will be saved.
* `chart-type:` The type of chart to generate. Choose between "sunburst" and "treemap".
* `device:` The device to be used by SentenceTransformer. Choose between "cpu" and "cuda".
* `model-name:` The name of the SentenceTransformer model to use. For available models, refer to the SentenceTransformers documentation.
* `min-similarity:` The minimum similarity for clustering. It's a value between 0 and 1, where 1 means exact match and 0 means no match at all.
* `remove-dupes:` Whether to remove duplicates from the dataset.
* `volume:` The name of the column containing numerical values. If --volume is used, the keyword with the largest volume will be used as the name of the cluster. If not, the shortest word will be used.
* `stem:` Whether to perform stemming on the 'hub' column.

## Dependencies

The script depends on several Python libraries:

* os, platform, string, time: Standard Python libraries for various system-level tasks.
* collections: For creating a Counter object.
* chardet: For detecting the character encoding of the CSV file.
* numpy and pandas: For data manipulation and analysis.
* plotly.express and plotly.io: For data visualization.
* typer: For creating a command-line interface.
* win32com.client: For saving the output as an Excel pivot table.
* polyfuzz: For clustering similar texts.
* rich: For creating rich console output.
* sentence_transformers: For generating sentence embeddings.

Make sure to install these dependencies before running the script:

`pip install chardet numpy pandas plotly typer pywin32 polyfuzz rich sentence_transformers`

## Additional Notes
Please note that this script uses SentenceTransformers, which under the hood uses PyTorch. Therefore, it's recommended to run this script on a machine with a decent amount of RAM. Also, if you choose to use a GPU (--device "cuda"), make sure that you have a CUDA-compatible GPU and that the correct version of PyTorch is installed.

For very large datasets, you will need a lot of RAM! A couple of ways to work around this is to 1) Set a very large page file, or use a lighter sentence transformer.
